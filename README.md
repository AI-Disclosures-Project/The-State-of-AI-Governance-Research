![logo](logo/green+orange-full-color_lrg.jpg) 

# The State of AI Governance Research
### AI safety and reliability in real world commercial deployment

The official GitHub repository for the paper "The State of AI Governance Research" by [The AI Disclosures Project](https://www.ssrc.org/programs/ai-disclosures-project/).


Using a comprehensive new dataset of 1,178 safety and reliability papers from 9,439 generative AI papers (January 2020 - March 2025), we compare the research outputs of leading AI companies (*Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI*) with leading AI universities (*CMU, NYU, Stanford, University of Washington, and UC Berkeley*). Our analysis shows that corporate AI research significantly shapes the field today through its research priorities, its framing of the problems, and its dominance in citations. We find that corporate governance research has shifted primarily toward model alignment and testing \& evaluation in the pre-deployment stage, while moving away from issues of model bias (which is normally detected during deployment) -- a shift that reflects commercial product priorities and existential risk concerns. We note a dearth of AI research addressing high-risk post-deployment contexts, including applications in healthcare, commercial settings, finance, and from misinformation and disinformation, behavioral features such as persuasiveness and addictiveness, and the failure to disclose information about contested areas such as use of copyrighted material in training. To advance AI research in these neglected areas, we recommend measures that improve external data access and observability into deployed AI systems' behaviors.
